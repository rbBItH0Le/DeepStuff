{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST=tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(training_images,training_labels),(testing_images,test_label)=MNIST.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ba73d67c40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images=training_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_images=testing_images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.6426 - accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ba7298bbb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 1s 522us/step - loss: 0.3757 - accuracy: 0.8645\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.3348 - accuracy: 0.8765\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 1s 521us/step - loss: 0.3155 - accuracy: 0.8856\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 1s 517us/step - loss: 0.2950 - accuracy: 0.8908\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 1s 519us/step - loss: 0.2812 - accuracy: 0.8960\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 1s 520us/step - loss: 0.2690 - accuracy: 0.8996\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.2579 - accuracy: 0.9045\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 0.2482 - accuracy: 0.9071\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 0.2401 - accuracy: 0.9090\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 1s 543us/step - loss: 0.2325 - accuracy: 0.9129\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 1s 542us/step - loss: 0.2244 - accuracy: 0.9151\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 1s 530us/step - loss: 0.2190 - accuracy: 0.9176\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.2100 - accuracy: 0.9203\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.2038 - accuracy: 0.9233\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.2005 - accuracy: 0.9238\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.1946 - accuracy: 0.9273\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 0.1887 - accuracy: 0.9290\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 1s 547us/step - loss: 0.1845 - accuracy: 0.9306\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 1s 549us/step - loss: 0.1803 - accuracy: 0.9314\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 1s 537us/step - loss: 0.1738 - accuracy: 0.9346\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 1s 553us/step - loss: 0.1700 - accuracy: 0.9360\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 1s 723us/step - loss: 0.1679 - accuracy: 0.9369\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.1619 - accuracy: 0.9388\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 1s 537us/step - loss: 0.1569 - accuracy: 0.9411\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 1s 575us/step - loss: 0.1536 - accuracy: 0.9427\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 1s 571us/step - loss: 0.1521 - accuracy: 0.9433\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.1482 - accuracy: 0.9437\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 1s 568us/step - loss: 0.1445 - accuracy: 0.9458\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.1423 - accuracy: 0.9463\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.1386 - accuracy: 0.9481\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.1368 - accuracy: 0.9484\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.1319 - accuracy: 0.9503\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.1290 - accuracy: 0.9517\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.1267 - accuracy: 0.9532\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.1236 - accuracy: 0.9542\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 1s 537us/step - loss: 0.1231 - accuracy: 0.9537\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.1202 - accuracy: 0.9548\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.1174 - accuracy: 0.9563\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 1s 542us/step - loss: 0.1159 - accuracy: 0.9568\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.1125 - accuracy: 0.9587\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.1133 - accuracy: 0.9583\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.1093 - accuracy: 0.9586\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.1067 - accuracy: 0.9603\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.1081 - accuracy: 0.9593\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.1044 - accuracy: 0.9611\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 1s 561us/step - loss: 0.1029 - accuracy: 0.9619\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 1s 589us/step - loss: 0.1026 - accuracy: 0.9611\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 1s 586us/step - loss: 0.1001 - accuracy: 0.9630\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 1s 579us/step - loss: 0.0957 - accuracy: 0.9647\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 1s 578us/step - loss: 0.0953 - accuracy: 0.9646\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 1s 555us/step - loss: 0.0945 - accuracy: 0.9650\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 1s 546us/step - loss: 0.0933 - accuracy: 0.9656\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.0897 - accuracy: 0.9671\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 1s 564us/step - loss: 0.0898 - accuracy: 0.9672\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 1s 574us/step - loss: 0.0887 - accuracy: 0.9664\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.0872 - accuracy: 0.9676\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 1s 533us/step - loss: 0.0858 - accuracy: 0.9673\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 1s 541us/step - loss: 0.0827 - accuracy: 0.9689\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.0837 - accuracy: 0.9683\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.0817 - accuracy: 0.9695\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.0826 - accuracy: 0.9693\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.0789 - accuracy: 0.9707\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.0790 - accuracy: 0.9703\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 1s 537us/step - loss: 0.0807 - accuracy: 0.9694\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.0758 - accuracy: 0.9722\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 1s 537us/step - loss: 0.0767 - accuracy: 0.9713\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.0730 - accuracy: 0.9725\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.0740 - accuracy: 0.9722\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.0722 - accuracy: 0.9734\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 1s 547us/step - loss: 0.0715 - accuracy: 0.9725\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 1s 534us/step - loss: 0.0708 - accuracy: 0.9730\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 0.0725 - accuracy: 0.9731\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 1s 581us/step - loss: 0.0687 - accuracy: 0.9746\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 1s 583us/step - loss: 0.0691 - accuracy: 0.9742\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 1s 572us/step - loss: 0.0635 - accuracy: 0.9766\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 1s 554us/step - loss: 0.0666 - accuracy: 0.9757\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 1s 571us/step - loss: 0.0657 - accuracy: 0.9759\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 553us/step - loss: 0.0641 - accuracy: 0.9755\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 1s 544us/step - loss: 0.0655 - accuracy: 0.9750\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 1s 548us/step - loss: 0.0620 - accuracy: 0.9774\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 1s 553us/step - loss: 0.0632 - accuracy: 0.9763\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 1s 563us/step - loss: 0.0621 - accuracy: 0.9769\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 1s 558us/step - loss: 0.0607 - accuracy: 0.9772\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 1s 552us/step - loss: 0.0602 - accuracy: 0.9774\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.0606 - accuracy: 0.9778\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 1s 547us/step - loss: 0.0574 - accuracy: 0.9790\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 1s 546us/step - loss: 0.0627 - accuracy: 0.9776\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 0.0574 - accuracy: 0.9786\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 1s 543us/step - loss: 0.0558 - accuracy: 0.9790\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 1s 552us/step - loss: 0.0593 - accuracy: 0.9787\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 1s 579us/step - loss: 0.0532 - accuracy: 0.9804\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.0525 - accuracy: 0.9805\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.0548 - accuracy: 0.9797\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.0544 - accuracy: 0.9805\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 1s 542us/step - loss: 0.0521 - accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.0531 - accuracy: 0.9799\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 1s 539us/step - loss: 0.0510 - accuracy: 0.9808\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.0510 - accuracy: 0.9805\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 1s 535us/step - loss: 0.0516 - accuracy: 0.9807\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 1s 538us/step - loss: 0.0520 - accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ba72ffe400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images,training_labels,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 396us/step - loss: 0.7777 - accuracy: 0.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.777711033821106, 0.8853999972343445]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testing_images,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mycallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        if(logs.get('loss')<0.4):\n",
    "            print(\"reached required accuracy\")\n",
    "            self.model.stop_training=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=mycallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
